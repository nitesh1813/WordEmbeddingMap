{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.main(['install','/datasets/home/34/234/cs291gbl/fastText/. --user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pip\n",
    "import torch\n",
    "from torch import nn\n",
    "import fastText\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import io\n",
    "from scipy import linalg\n",
    "# import torch\n",
    "print(torch.__version__)\n",
    "from scipy.stats import spearmanr\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embeddings(path):\n",
    "    \"\"\"\n",
    "    Reload pretrained embeddings from a text file.\n",
    "    \"\"\"\n",
    "    word2id = {}\n",
    "    vectors = []\n",
    "    id2word={}\n",
    "    emb_path =path\n",
    "    _emb_dim_file = 300\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                split = line.split()\n",
    "               \n",
    "            else:\n",
    "                word, vect = line.rstrip().split(' ', 1)\n",
    "                \n",
    "                word = word.lower()\n",
    "                vect = np.fromstring(vect, sep=' ')\n",
    "                if np.linalg.norm(vect) == 0:  # avoid to have null embeddings\n",
    "                    vect[0] = 0.01\n",
    "               \n",
    "                word2id[word] = len(word2id)\n",
    "                id2word[len(word2id)]=word\n",
    "#                 print(word)\n",
    "                vectors.append(vect[None])\n",
    "            if len(word2id) >= 200000:\n",
    "                break\n",
    "\n",
    "    \n",
    "    print(\"Loaded %i pre-trained word embeddings.\" % len(vectors))\n",
    "\n",
    "\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.concatenate(vectors, 0)\n",
    "    embeddings = torch.from_numpy(embeddings).float()\n",
    "    embeddings = embeddings.cuda()\n",
    "    \n",
    "    return embeddings,word2id,id2word\n",
    "\n",
    "\n",
    "def load_fasttext_model(path):\n",
    "    return fastText.load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dis_xy(bs, src_emb,tgt_emb):\n",
    "        \"\"\"\n",
    "        Get discriminator input batch / output target.\n",
    "        \"\"\"\n",
    "        # select random word IDs\n",
    "        #bs = self.params.batch_size\n",
    "        mf = 75000\n",
    "        #assert mf <= min(len(self.src_dico), len(self.tgt_dico))\n",
    "        src_ids = torch.LongTensor(bs).random_(mf)\n",
    "        tgt_ids = torch.LongTensor(bs).random_(mf)\n",
    "        \n",
    "        src_ids = src_ids.cuda()\n",
    "        tgt_ids = tgt_ids.cuda()\n",
    "\n",
    "        # get word embeddings\n",
    "        src_emb = src_emb(Variable(src_ids))\n",
    "        tgt_emb = tgt_emb(Variable(tgt_ids))\n",
    "        src_emb = mapping(Variable(src_emb.data))\n",
    "        tgt_emb = Variable(tgt_emb.data)\n",
    "\n",
    "        # input / target\n",
    "        x = torch.cat([src_emb, tgt_emb], 0)\n",
    "        y = torch.FloatTensor(2 * bs).zero_()\n",
    "        y[:bs] = 1 - 0.1\n",
    "        y[bs:] = 0.1\n",
    "        y = Variable(y.cuda())\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200000 pre-trained word embeddings.\n",
      "Loaded 200000 pre-trained word embeddings.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# english=load_fasttext_model(\"data/wiki.en.bin\")\n",
    "# spanish=load_fasttext_model(\"data/wiki.es.bin\")\n",
    "src_embedding,src_word2id,src_id2word=load_pretrained_embeddings(\"data/wiki.en.vec\")\n",
    "tgt_embedding,tgt_word2id,tgt_id2word=load_pretrained_embeddings(\"data/wiki.es.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(200000, 300, sparse=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_embeddings = nn.Embedding(200000, 300, sparse=True)\n",
    "src_embeddings.weight.data.copy_(src_embedding)\n",
    "\n",
    "tgt_embeddings = nn.Embedding(200000, 300, sparse=True)\n",
    "tgt_embeddings.weight.data.copy_(tgt_embedding)\n",
    "\n",
    "src_embeddings.cuda()\n",
    "tgt_embeddings.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch2(X,batch_size):\n",
    " \n",
    "#     N = X.size()[0]\n",
    "    N=200000\n",
    "    batch_indices = torch.LongTensor( np.random.randint(0,N,size=batch_size) )\n",
    "\n",
    "    batch_xs = X(Variable(batch_indices).cuda())\n",
    "\n",
    "    return batch_xs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, dis_hid_dim,dis_dropout,dis_input_dropout):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.emb_dim = 300\n",
    "        self.dis_layers = 2\n",
    "        self.dis_hid_dim = dis_hid_dim\n",
    "        self.dis_dropout = dis_dropout\n",
    "        self.dis_input_dropout = dis_input_dropout\n",
    "\n",
    "        layers = [nn.Dropout(self.dis_input_dropout)]\n",
    "        for i in range(self.dis_layers + 1):\n",
    "            input_dim = self.emb_dim if i == 0 else self.dis_hid_dim\n",
    "            output_dim = 1 if i == self.dis_layers else self.dis_hid_dim\n",
    "            layers.append(nn.Linear(input_dim, output_dim))\n",
    "            if i < self.dis_layers:\n",
    "                layers.append(nn.LeakyReLU(0.2))\n",
    "                layers.append(nn.Dropout(self.dis_dropout))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.dim() == 2 and x.size(1) == self.emb_dim\n",
    "        return self.layers(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Orthogonal(beta):\n",
    "    global mapping\n",
    "    W=mapping.weight.data\n",
    "    mapping.weight.data.copy_((1 + beta) * W - beta * W.mm(W.transpose(0, 1).mm(W)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (layers): Sequential(\n",
       "    (0): Dropout(p=0.1)\n",
       "    (1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(0.2)\n",
       "    (3): Dropout(p=0)\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): LeakyReLU(0.2)\n",
       "    (6): Dropout(p=0)\n",
       "    (7): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up linear mapping,\n",
    "mapping = nn.Linear(300, 300, bias=False)\n",
    "mapping.weight.data.copy_(torch.eye(300))\n",
    "modelDisc= Discriminator(2048,0,0.1)\n",
    "mapping.cuda()\n",
    "modelDisc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csls(src_emb, tgt_emb, knn=10):\n",
    " \n",
    "    bs = 1024\n",
    "    all_distances = []\n",
    "#     emb = tgt_emb.transpose(0, 1).contiguous()\n",
    "    emb=tgt_emb.transpose(0,1)\n",
    "    for i in range(0, src_emb.shape[0], bs):\n",
    "        distances = src_emb[i:i + bs].mm(emb)\n",
    "        best_distances, _ = distances.topk(knn, dim=1, largest=True, sorted=True)\n",
    "        all_distances.append(best_distances.mean(1).cpu())\n",
    "    all_distances = torch.cat(all_distances)\n",
    "    return all_distances.numpy()\n",
    "\n",
    "def get_neighbour(emb1,emb2):\n",
    "    bs = 128\n",
    "\n",
    "    all_scores = []\n",
    "    all_targets = []\n",
    "\n",
    "    # number of source words to consider\n",
    "    n_src = emb1.size(0)\n",
    "    n_src =30000\n",
    "    knn = 10\n",
    "\n",
    "        # average distances to k nearest neighbors\n",
    "#     average_dist1 = torch.from_numpy(get_csls(emb1, emb2, knn))\n",
    "#     average_dist2 = torch.from_numpy(get_csls(emb2, emb1, knn))\n",
    "#     average_dist1 = average_dist1.type_as(emb1)\n",
    "#     average_dist2 = average_dist2.type_as(emb2)\n",
    "\n",
    "    # for every source word\n",
    "    for i in range(0, n_src, bs):\n",
    "\n",
    "        # compute target words scores\n",
    "        scores = emb2.mm(emb1[i:min(n_src, i + bs)].transpose(0, 1)).transpose(0, 1)\n",
    "        scores.mul_(2)\n",
    "#         scores.sub_(average_dist1[i:min(n_src, i + bs)][:, None] + average_dist2[None, :])\n",
    "        best_scores, best_targets = scores.topk(2, dim=1, largest=True, sorted=True)\n",
    "\n",
    "        # update scores / potential targets\n",
    "        all_scores.append(best_scores.cpu())\n",
    "        all_targets.append(best_targets.cpu())\n",
    "\n",
    "    all_scores = torch.cat(all_scores, 0)\n",
    "    all_targets = torch.cat(all_targets, 0)\n",
    "\n",
    "    all_pairs = torch.cat([torch.arange(0, all_targets.size(0)).long().unsqueeze(1),all_targets[:, 0].unsqueeze(1)], 1)\n",
    "    assert all_scores.size() == all_pairs.size() == (n_src, 2)\n",
    "\n",
    "    # sort pairs by score confidence\n",
    "    diff = all_scores[:, 0] - all_scores[:, 1]\n",
    "    reordered = diff.sort(0, descending=True)[1]\n",
    "    all_scores = all_scores[reordered]\n",
    "    all_pairs = all_pairs[reordered]\n",
    "    \n",
    "    \n",
    "    selected = all_pairs.max(1)[0] <= 30000\n",
    "    mask = selected.unsqueeze(1).expand_as(all_scores).clone()\n",
    "    all_scores = all_scores.masked_select(mask).view(-1, 2)\n",
    "    all_pairs = all_pairs.masked_select(mask).view(-1, 2)\n",
    "    return all_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dictionary(src_embedding,tgt_embedding):\n",
    "    src2tgt = get_neighbour(src_embedding,tgt_embedding)\n",
    "    tgt2src = get_neighbour(tgt_embedding,src_embedding)\n",
    "    tgt2src = torch.cat([tgt2src[:, 1:], tgt2src[:, :1]], 1)\n",
    "    \n",
    "    s2t_candidates = set([(a, b) for a, b in src2tgt])\n",
    "    t2s_candidates = set([(a, b) for a, b in tgt2src])\n",
    "    \n",
    "\n",
    "#     print(s2t_candidates)\n",
    "    final_pairs = s2t_candidates & t2s_candidates\n",
    "    if len(final_pairs) == 0:\n",
    "        print(\"warning\")\n",
    "        return None\n",
    "    dictionary = torch.LongTensor(list([[a, b] for (a, b) in final_pairs]))\n",
    "\n",
    "    print('New train dictionary of %i pairs.' % dictionary.size(0))\n",
    "    return dictionary.cuda()\n",
    "    \n",
    "        \n",
    "# def build_dictionary(src_emb, tgt_emb, _params, s2t_candidates, t2s_candidates):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metric(src_embs, tgt_embs):\n",
    "        global mapping\n",
    "        indices= torch.LongTensor(np.arange(200000))\n",
    "        batch_xs = src_embs(Variable(indices).cuda())\n",
    "        src_emb = mapping(batch_xs.cuda())\n",
    "        src_emb=torch.FloatTensor(src_emb.cpu().data.numpy())\n",
    "        tgt_emb = tgt_embs(Variable(indices).cuda())\n",
    "        tgt_emb=torch.FloatTensor(tgt_emb.cpu().data.numpy())\n",
    "        src_emb = src_emb / src_emb.norm(2, 1, keepdim=True).expand_as(src_emb)\n",
    "        tgt_emb = tgt_emb / tgt_emb.norm(2, 1, keepdim=True).expand_as(tgt_emb)\n",
    "#         monolingual_wordsim(src_emb,tgt_emb)\n",
    "\n",
    "        dictionary = create_dictionary(src_emb, tgt_emb)\n",
    "        dictionary_max_size = 10000\n",
    "        if dictionary is None:\n",
    "            mean_cosine=0\n",
    "        else:\n",
    "            mean_cosine = (src_emb[dictionary[:dictionary_max_size, 0]] * tgt_emb[dictionary[:dictionary_max_size, 1]]).sum(1).mean()\n",
    "        print(\"Mean cosine\", mean_cosine)\n",
    "        return mean_cosine\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "linoptimizer = torch.optim.SGD(mapping.parameters(), lr=0.1)\n",
    "discoptimizer= torch.optim.SGD(modelDisc.parameters(), lr=0.1)\n",
    "\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "\n",
    "def get_xy():\n",
    "    global mapping\n",
    "    \n",
    "#get minibatch of spanish words\n",
    "    spanish_batch=get_batch2(tgt_embeddings,batch_size)\n",
    "    #getminibatch of english words\n",
    "    english_batch=get_batch2(src_embeddings,batch_size)\n",
    "\n",
    "    #generate fake spanish embeddings\n",
    "    s_fake= mapping(english_batch)\n",
    "\n",
    "    #stack real and fake\n",
    "    x = torch.cat([s_fake, spanish_batch], 0)\n",
    "    #         print(x.shape)\n",
    "    y = torch.FloatTensor(2 * batch_size).zero_()\n",
    "    \n",
    "    y[batch_size:] = 0.1\n",
    "    y[:batch_size]=1-0.1\n",
    "    y=Variable(y).cuda()\n",
    "    return x,y\n",
    "\n",
    "def train_disc():\n",
    "    modelDisc.train()\n",
    "  \n",
    "    x,y=get_dis_xy(32,src_embeddings,tgt_embeddings)\n",
    "    y_pred = modelDisc(Variable(x.data))\n",
    "    loss= F.binary_cross_entropy(y_pred, y)\n",
    "    discoptimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    discoptimizer.step()\n",
    "    return loss.data\n",
    "    \n",
    "def train_gen():\n",
    "    modelDisc.eval()\n",
    "   \n",
    "    x,y=get_dis_xy(32,src_embeddings,tgt_embeddings)\n",
    "    y=1-y\n",
    "    y_pred = modelDisc(x)\n",
    "    loss2= F.binary_cross_entropy(y_pred, y)\n",
    "    linoptimizer.zero_grad()\n",
    "    loss2.backward()\n",
    "    linoptimizer.step()\n",
    "\n",
    "    Orthogonal(0.001)\n",
    "    return loss2.data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3201465607\n",
      "(0, ' Discriminator Loss :  ', \n",
      " 0.6248\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 0.7853\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "17.2130451202\n",
      "(4000, ' Discriminator Loss :  ', \n",
      " 0.5119\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2151\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "17.0147075653\n",
      "(8000, ' Discriminator Loss :  ', \n",
      " 0.5431\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.3528\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.8599033356\n",
      "(12000, ' Discriminator Loss :  ', \n",
      " 0.5203\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2978\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6919116974\n",
      "(16000, ' Discriminator Loss :  ', \n",
      " 0.5206\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2154\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5841236115\n",
      "(20000, ' Discriminator Loss :  ', \n",
      " 0.5053\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1619\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4782867432\n",
      "(24000, ' Discriminator Loss :  ', \n",
      " 0.5295\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2356\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4050750732\n",
      "(28000, ' Discriminator Loss :  ', \n",
      " 0.4689\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2893\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3849411011\n",
      "(32000, ' Discriminator Loss :  ', \n",
      " 0.5323\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.5927\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3688468933\n",
      "(36000, ' Discriminator Loss :  ', \n",
      " 0.4340\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2677\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.333612442\n",
      "(40000, ' Discriminator Loss :  ', \n",
      " 0.4867\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6609\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3282833099\n",
      "(44000, ' Discriminator Loss :  ', \n",
      " 0.4515\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.4908\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3257026672\n",
      "(48000, ' Discriminator Loss :  ', \n",
      " 0.4681\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7220\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3162593842\n",
      "(52000, ' Discriminator Loss :  ', \n",
      " 0.5059\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6086\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.271156311\n",
      "(56000, ' Discriminator Loss :  ', \n",
      " 0.4712\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6947\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2433700562\n",
      "(60000, ' Discriminator Loss :  ', \n",
      " 0.4205\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6917\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2291908264\n",
      "(64000, ' Discriminator Loss :  ', \n",
      " 0.4345\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6215\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.220161438\n",
      "(68000, ' Discriminator Loss :  ', \n",
      " 0.4682\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9297\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2367916107\n",
      "(72000, ' Discriminator Loss :  ', \n",
      " 0.4019\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8946\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2518978119\n",
      "(76000, ' Discriminator Loss :  ', \n",
      " 0.4266\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6748\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.247713089\n",
      "(80000, ' Discriminator Loss :  ', \n",
      " 0.4381\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8303\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2542266846\n",
      "(84000, ' Discriminator Loss :  ', \n",
      " 0.3918\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6431\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2281398773\n",
      "(88000, ' Discriminator Loss :  ', \n",
      " 0.4542\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7923\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2156352997\n",
      "(92000, ' Discriminator Loss :  ', \n",
      " 0.4389\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8729\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2333316803\n",
      "(96000, ' Discriminator Loss :  ', \n",
      " 0.4296\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7282\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "                 EN_SIMLEX-999        998             1       0.3851\n",
      "                   EN_VERB-143        144             0       0.3551\n",
      "                      EN_MC-30         30             0       0.8116\n",
      "                EN_RW-STANFORD       1323           711       0.5056\n",
      "                      EN_RG-65         65             0       0.7901\n",
      "                 EN_WS-353-ALL        353             0       0.7246\n",
      "                     EN_YP-130        130             0       0.5175\n",
      "                  EN_MTurk-771        771             0       0.6564\n",
      "                 EN_WS-353-SIM        203             0       0.7878\n",
      "                  EN_MEN-TR-3k       3000             0       0.7536\n",
      "                 EN_WS-353-REL        252             0       0.6511\n",
      "                  EN_SEMEVAL17        379             9       0.7098\n",
      "                  EN_MTurk-287        286             1       0.6482\n",
      "                     ES_WS-353        319            33       0.6126\n",
      "                      ES_MC-30         27             3       0.7475\n",
      "                  ES_SEMEVAL17        368            10       0.7391\n",
      "                      ES_RG-65         65             0       0.8794\n",
      "Monolingual source word similarity score average: 0.63820\n",
      "Monolingual target word similarity score average: 0.74466\n",
      "Monolingual word similarity score average: 0.69143\n",
      "16.2648887634\n",
      "(0, ' Discriminator Loss :  ', \n",
      " 0.4043\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8723\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2752857208\n",
      "(4000, ' Discriminator Loss :  ', \n",
      " 0.4452\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6818\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2825984955\n",
      "(8000, ' Discriminator Loss :  ', \n",
      " 0.3972\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8946\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2953147888\n",
      "(12000, ' Discriminator Loss :  ', \n",
      " 0.3909\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7246\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2965698242\n",
      "(16000, ' Discriminator Loss :  ', \n",
      " 0.4084\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8294\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2951202393\n",
      "(20000, ' Discriminator Loss :  ', \n",
      " 0.4824\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9030\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2909870148\n",
      "(24000, ' Discriminator Loss :  ', \n",
      " 0.4239\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8860\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2994441986\n",
      "(28000, ' Discriminator Loss :  ', \n",
      " 0.4255\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8859\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3128185272\n",
      "(32000, ' Discriminator Loss :  ', \n",
      " 0.4253\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8394\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3306694031\n",
      "(36000, ' Discriminator Loss :  ', \n",
      " 0.4483\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8843\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3312988281\n",
      "(40000, ' Discriminator Loss :  ', \n",
      " 0.4394\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8161\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3376197815\n",
      "(44000, ' Discriminator Loss :  ', \n",
      " 0.4307\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9502\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3610572815\n",
      "(48000, ' Discriminator Loss :  ', \n",
      " 0.4051\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0062\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3818340302\n",
      "(52000, ' Discriminator Loss :  ', \n",
      " 0.4349\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8768\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.3647460938\n",
      "(56000, ' Discriminator Loss :  ', \n",
      " 0.4518\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8624\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3865680695\n",
      "(60000, ' Discriminator Loss :  ', \n",
      " 0.3972\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8638\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3838310242\n",
      "(64000, ' Discriminator Loss :  ', \n",
      " 0.4123\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8356\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3631019592\n",
      "(68000, ' Discriminator Loss :  ', \n",
      " 0.4053\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0015\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3631248474\n",
      "(72000, ' Discriminator Loss :  ', \n",
      " 0.3773\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6503\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3747882843\n",
      "(76000, ' Discriminator Loss :  ', \n",
      " 0.4512\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0184\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3857841492\n",
      "(80000, ' Discriminator Loss :  ', \n",
      " 0.4105\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7908\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4048938751\n",
      "(84000, ' Discriminator Loss :  ', \n",
      " 0.4342\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8809\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3800010681\n",
      "(88000, ' Discriminator Loss :  ', \n",
      " 0.4894\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0613\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3934211731\n",
      "(92000, ' Discriminator Loss :  ', \n",
      " 0.4522\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8559\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3943214417\n",
      "(96000, ' Discriminator Loss :  ', \n",
      " 0.4134\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0420\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "                 EN_SIMLEX-999        998             1       0.3675\n",
      "                   EN_VERB-143        144             0       0.3678\n",
      "                      EN_MC-30         30             0       0.8296\n",
      "                EN_RW-STANFORD       1323           711       0.5007\n",
      "                      EN_RG-65         65             0       0.7621\n",
      "                 EN_WS-353-ALL        353             0       0.7117\n",
      "                     EN_YP-130        130             0       0.5057\n",
      "                  EN_MTurk-771        771             0       0.6439\n",
      "                 EN_WS-353-SIM        203             0       0.7546\n",
      "                  EN_MEN-TR-3k       3000             0       0.7437\n",
      "                 EN_WS-353-REL        252             0       0.6502\n",
      "                  EN_SEMEVAL17        379             9       0.7242\n",
      "                  EN_MTurk-287        286             1       0.6364\n",
      "                     ES_WS-353        319            33       0.6126\n",
      "                      ES_MC-30         27             3       0.7475\n",
      "                  ES_SEMEVAL17        368            10       0.7391\n",
      "                      ES_RG-65         65             0       0.8794\n",
      "Monolingual source word similarity score average: 0.63062\n",
      "Monolingual target word similarity score average: 0.74466\n",
      "Monolingual word similarity score average: 0.68764\n",
      "16.3852844238\n",
      "(0, ' Discriminator Loss :  ', \n",
      " 0.4309\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9116\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4042835236\n",
      "(4000, ' Discriminator Loss :  ', \n",
      " 0.3994\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9378\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3945503235\n",
      "(8000, ' Discriminator Loss :  ', \n",
      " 0.3808\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9750\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4063625336\n",
      "(12000, ' Discriminator Loss :  ', \n",
      " 0.4290\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8194\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3875961304\n",
      "(16000, ' Discriminator Loss :  ', \n",
      " 0.4010\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9963\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3874225616\n",
      "(20000, ' Discriminator Loss :  ', \n",
      " 0.3785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9647\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3969516754\n",
      "(24000, ' Discriminator Loss :  ', \n",
      " 0.4063\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0164\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3942947388\n",
      "(28000, ' Discriminator Loss :  ', \n",
      " 0.4255\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0127\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4145851135\n",
      "(32000, ' Discriminator Loss :  ', \n",
      " 0.4050\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8435\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4033699036\n",
      "(36000, ' Discriminator Loss :  ', \n",
      " 0.4226\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4220485687\n",
      "(40000, ' Discriminator Loss :  ', \n",
      " 0.4264\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7577\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4320354462\n",
      "(44000, ' Discriminator Loss :  ', \n",
      " 0.4290\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9513\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4164619446\n",
      "(48000, ' Discriminator Loss :  ', \n",
      " 0.4245\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8963\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4462451935\n",
      "(52000, ' Discriminator Loss :  ', \n",
      " 0.3831\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8030\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.45545578\n",
      "(56000, ' Discriminator Loss :  ', \n",
      " 0.4095\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8027\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4503097534\n",
      "(60000, ' Discriminator Loss :  ', \n",
      " 0.4073\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9890\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4650402069\n",
      "(64000, ' Discriminator Loss :  ', \n",
      " 0.3978\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7628\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.45652771\n",
      "(68000, ' Discriminator Loss :  ', \n",
      " 0.3912\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9868\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4700584412\n",
      "(72000, ' Discriminator Loss :  ', \n",
      " 0.3877\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9100\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.4867248535\n",
      "(76000, ' Discriminator Loss :  ', \n",
      " 0.4326\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7410\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5012073517\n",
      "(80000, ' Discriminator Loss :  ', \n",
      " 0.4273\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8531\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5023651123\n",
      "(84000, ' Discriminator Loss :  ', \n",
      " 0.4467\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9332\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5061016083\n",
      "(88000, ' Discriminator Loss :  ', \n",
      " 0.4250\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9673\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5060977936\n",
      "(92000, ' Discriminator Loss :  ', \n",
      " 0.3879\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0802\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5099124908\n",
      "(96000, ' Discriminator Loss :  ', \n",
      " 0.4158\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0610\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "                 EN_SIMLEX-999        998             1       0.3752\n",
      "                   EN_VERB-143        144             0       0.3761\n",
      "                      EN_MC-30         30             0       0.8486\n",
      "                EN_RW-STANFORD       1323           711       0.4919\n",
      "                      EN_RG-65         65             0       0.8051\n",
      "                 EN_WS-353-ALL        353             0       0.7101\n",
      "                     EN_YP-130        130             0       0.5060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  EN_MTurk-771        771             0       0.6420\n",
      "                 EN_WS-353-SIM        203             0       0.7658\n",
      "                  EN_MEN-TR-3k       3000             0       0.7508\n",
      "                 EN_WS-353-REL        252             0       0.6502\n",
      "                  EN_SEMEVAL17        379             9       0.7071\n",
      "                  EN_MTurk-287        286             1       0.6726\n",
      "                     ES_WS-353        319            33       0.6126\n",
      "                      ES_MC-30         27             3       0.7475\n",
      "                  ES_SEMEVAL17        368            10       0.7391\n",
      "                      ES_RG-65         65             0       0.8794\n",
      "Monolingual source word similarity score average: 0.63856\n",
      "Monolingual target word similarity score average: 0.74466\n",
      "Monolingual word similarity score average: 0.69161\n",
      "16.5034122467\n",
      "(0, ' Discriminator Loss :  ', \n",
      " 0.4109\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9901\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5068855286\n",
      "(4000, ' Discriminator Loss :  ', \n",
      " 0.4327\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8374\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5042934418\n",
      "(8000, ' Discriminator Loss :  ', \n",
      " 0.3902\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0349\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5187740326\n",
      "(12000, ' Discriminator Loss :  ', \n",
      " 0.4102\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7736\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5455932617\n",
      "(16000, ' Discriminator Loss :  ', \n",
      " 0.4416\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9595\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5552444458\n",
      "(20000, ' Discriminator Loss :  ', \n",
      " 0.4372\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8816\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5499324799\n",
      "(24000, ' Discriminator Loss :  ', \n",
      " 0.4234\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6775\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5612773895\n",
      "(28000, ' Discriminator Loss :  ', \n",
      " 0.4417\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.1385\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5806713104\n",
      "(32000, ' Discriminator Loss :  ', \n",
      " 0.3731\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9779\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5746574402\n",
      "(36000, ' Discriminator Loss :  ', \n",
      " 0.4265\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.1071\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5968513489\n",
      "(40000, ' Discriminator Loss :  ', \n",
      " 0.4396\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9135\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6083469391\n",
      "(44000, ' Discriminator Loss :  ', \n",
      " 0.4474\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8506\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6281509399\n",
      "(48000, ' Discriminator Loss :  ', \n",
      " 0.4388\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.5989\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6241111755\n",
      "(52000, ' Discriminator Loss :  ', \n",
      " 0.4660\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8652\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6459579468\n",
      "(56000, ' Discriminator Loss :  ', \n",
      " 0.4088\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8727\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6562576294\n",
      "(60000, ' Discriminator Loss :  ', \n",
      " 0.4281\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8847\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6745967865\n",
      "(64000, ' Discriminator Loss :  ', \n",
      " 0.3932\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8823\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6739196777\n",
      "(68000, ' Discriminator Loss :  ', \n",
      " 0.3972\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7757\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6683006287\n",
      "(72000, ' Discriminator Loss :  ', \n",
      " 0.4162\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6701\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6614837646\n",
      "(76000, ' Discriminator Loss :  ', \n",
      " 0.4207\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8819\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6797485352\n",
      "(80000, ' Discriminator Loss :  ', \n",
      " 0.4080\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9357\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6957950592\n",
      "(84000, ' Discriminator Loss :  ', \n",
      " 0.4494\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8259\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6989822388\n",
      "(88000, ' Discriminator Loss :  ', \n",
      " 0.4456\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8586\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6969814301\n",
      "(92000, ' Discriminator Loss :  ', \n",
      " 0.4771\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.6760\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6884632111\n",
      "(96000, ' Discriminator Loss :  ', \n",
      " 0.4517\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8795\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "                 EN_SIMLEX-999        998             1       0.3803\n",
      "                   EN_VERB-143        144             0       0.3400\n",
      "                      EN_MC-30         30             0       0.7914\n",
      "                EN_RW-STANFORD       1323           711       0.4955\n",
      "                      EN_RG-65         65             0       0.8052\n",
      "                 EN_WS-353-ALL        353             0       0.7283\n",
      "                     EN_YP-130        130             0       0.5370\n",
      "                  EN_MTurk-771        771             0       0.6588\n",
      "                 EN_WS-353-SIM        203             0       0.7599\n",
      "                  EN_MEN-TR-3k       3000             0       0.7511\n",
      "                 EN_WS-353-REL        252             0       0.6698\n",
      "                  EN_SEMEVAL17        379             9       0.7096\n",
      "                  EN_MTurk-287        286             1       0.6856\n",
      "                     ES_WS-353        319            33       0.6126\n",
      "                      ES_MC-30         27             3       0.7475\n",
      "                  ES_SEMEVAL17        368            10       0.7391\n",
      "                      ES_RG-65         65             0       0.8794\n",
      "Monolingual source word similarity score average: 0.63942\n",
      "Monolingual target word similarity score average: 0.74466\n",
      "Monolingual word similarity score average: 0.69204\n",
      "16.7074680328\n",
      "(0, ' Discriminator Loss :  ', \n",
      " 0.4514\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0577\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6941223145\n",
      "(4000, ' Discriminator Loss :  ', \n",
      " 0.4352\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8069\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6819000244\n",
      "(8000, ' Discriminator Loss :  ', \n",
      " 0.4204\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8171\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6935710907\n",
      "(12000, ' Discriminator Loss :  ', \n",
      " 0.4536\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8507\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6717700958\n",
      "(16000, ' Discriminator Loss :  ', \n",
      " 0.4452\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8012\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6727809906\n",
      "(20000, ' Discriminator Loss :  ', \n",
      " 0.4140\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9516\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6616096497\n",
      "(24000, ' Discriminator Loss :  ', \n",
      " 0.4335\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7447\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6633930206\n",
      "(28000, ' Discriminator Loss :  ', \n",
      " 0.4319\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8302\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6866569519\n",
      "(32000, ' Discriminator Loss :  ', \n",
      " 0.4056\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8742\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.6912994385\n",
      "(36000, ' Discriminator Loss :  ', \n",
      " 0.4588\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9529\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7045478821\n",
      "(40000, ' Discriminator Loss :  ', \n",
      " 0.4086\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8113\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6991615295\n",
      "(44000, ' Discriminator Loss :  ', \n",
      " 0.3990\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8770\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6981296539\n",
      "(48000, ' Discriminator Loss :  ', \n",
      " 0.4347\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8289\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7183380127\n",
      "(52000, ' Discriminator Loss :  ', \n",
      " 0.4449\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7740\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7303962708\n",
      "(56000, ' Discriminator Loss :  ', \n",
      " 0.4511\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8046\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7163829803\n",
      "(60000, ' Discriminator Loss :  ', \n",
      " 0.3854\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8314\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7243652344\n",
      "(64000, ' Discriminator Loss :  ', \n",
      " 0.4084\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8056\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7516651154\n",
      "(68000, ' Discriminator Loss :  ', \n",
      " 0.4218\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9919\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7534160614\n",
      "(72000, ' Discriminator Loss :  ', \n",
      " 0.4326\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7616901398\n",
      "(76000, ' Discriminator Loss :  ', \n",
      " 0.4414\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7929\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7550010681\n",
      "(80000, ' Discriminator Loss :  ', \n",
      " 0.4146\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 2.0733\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7750835419\n",
      "(84000, ' Discriminator Loss :  ', \n",
      " 0.3971\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9313\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7696228027\n",
      "(88000, ' Discriminator Loss :  ', \n",
      " 0.4076\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.7540\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7579231262\n",
      "(92000, ' Discriminator Loss :  ', \n",
      " 0.4630\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.9161\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.7711658478\n",
      "(96000, ' Discriminator Loss :  ', \n",
      " 0.4263\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.8114\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "                 EN_SIMLEX-999        998             1       0.3794\n",
      "                   EN_VERB-143        144             0       0.3588\n",
      "                      EN_MC-30         30             0       0.8098\n",
      "                EN_RW-STANFORD       1323           711       0.5017\n",
      "                      EN_RG-65         65             0       0.8124\n",
      "                 EN_WS-353-ALL        353             0       0.7321\n",
      "                     EN_YP-130        130             0       0.5051\n",
      "                  EN_MTurk-771        771             0       0.6458\n",
      "                 EN_WS-353-SIM        203             0       0.7720\n",
      "                  EN_MEN-TR-3k       3000             0       0.7532\n",
      "                 EN_WS-353-REL        252             0       0.6825\n",
      "                  EN_SEMEVAL17        379             9       0.7076\n",
      "                  EN_MTurk-287        286             1       0.6844\n",
      "                     ES_WS-353        319            33       0.6126\n",
      "                      ES_MC-30         27             3       0.7475\n",
      "                  ES_SEMEVAL17        368            10       0.7391\n",
      "                      ES_RG-65         65             0       0.8794\n",
      "Monolingual source word similarity score average: 0.64189\n",
      "Monolingual target word similarity score average: 0.74466\n",
      "Monolingual word similarity score average: 0.69328\n"
     ]
    }
   ],
   "source": [
    "iterations_per_epoch=100000\n",
    "batch_size=32\n",
    "epoch=5\n",
    "val_score=-1\n",
    "\n",
    "for _ in range(epoch):\n",
    "      \n",
    "    for _n in range(0,iterations_per_epoch,batch_size):\n",
    "       \n",
    "        for __ in range(5):\n",
    "            loss=train_disc()\n",
    "\n",
    "            #x,y=get_xy()\n",
    "           \n",
    "          \n",
    "       \n",
    "        for __ in range(1):\n",
    "            loss2=train_gen()\n",
    "          \n",
    "            \n",
    "        if _n%500==0:\n",
    "            print(torch.norm(mapping.weight.data,2))\n",
    "            print(_n,\" Discriminator Loss :  \",loss)\n",
    "            print(\"Generator Loss : \", loss2)\n",
    "        \n",
    "    evaluation_metric(src_embeddings,tgt_embeddings)\n",
    "#     if val_score<val:\n",
    "#         torch.save(mapping.state_dict(), './mapping.pth')\n",
    "#         val_score=val\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train dictionary of 8405 pairs.\n"
     ]
    }
   ],
   "source": [
    "def build_dictionary(src_emb,tgt_emb):\n",
    "    src_emb = mapping(Variable(src_emb, requires_grad=False).cuda())\n",
    "    src_emb=torch.FloatTensor(src_emb.cpu().data.numpy()).cuda()\n",
    "    tgt_emb = tgt_emb.cuda()\n",
    "    src_emb = src_emb / src_emb.norm(2, 1, keepdim=True).expand_as(src_emb)\n",
    "    tgt_emb = tgt_emb / tgt_emb.norm(2, 1, keepdim=True).expand_as(tgt_emb)\n",
    "\n",
    "\n",
    "#         s2t_candidates = get_candidates(src_emb, tgt_emb, _params)\n",
    "#         t2s_candidates = get_candidates(tgt_emb, src_emb, _params)\n",
    "    dictionary= create_dictionary(src_emb, tgt_emb)\n",
    "    return dictionary\n",
    "\n",
    "dictionary=build_dictionary(src_embedding,tgt_embedding)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes(src_emb,tgt_emb):\n",
    "    A = src_emb.weight.data[list(dictionary[:, 0])]\n",
    "    B = tgt_emb.weight.data[list(dictionary[:, 1])]\n",
    "    M = B.transpose(0, 1).mm(A).cpu().numpy()\n",
    "    U, S, V_t = linalg.svd(M, full_matrices=True)\n",
    "    mapping.weight.data.copy_(torch.from_numpy(U.dot(V_t)).type_as(mapping.weight.data))\n",
    "# evaluation_metric(src_embeddings,tgt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.LongTensor\u001b[0m), but expected (torch.FloatTensor source, int dim, torch.LongTensor index)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-30d60858ed49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprocrustes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluation_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_score\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./mapping.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-3f2e9aa906fe>\u001b[0m in \u001b[0;36mevaluation_metric\u001b[0;34m(src_embs, tgt_embs)\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_embs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0msrc_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msrc_emb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/nn/modules/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/nn/_functions/thnn/sparse.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, indices, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.index_select received an invalid combination of arguments - got (\u001b[32;1mtorch.FloatTensor\u001b[0m, \u001b[32;1mint\u001b[0m, \u001b[31;1mtorch.cuda.LongTensor\u001b[0m), but expected (torch.FloatTensor source, int dim, torch.LongTensor index)"
     ]
    }
   ],
   "source": [
    "# print(dictionary[:, 0])\n",
    "for i in range(5):\n",
    "    procrustes(src_embeddings,tgt_embeddings)\n",
    "    val=evaluation_metric(src_embeddings,tgt_embeddings)\n",
    "    if val_score<val:\n",
    "        torch.save(mapping.state_dict(), './mapping.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 13861  23401\n",
       " 27039  19846\n",
       "  1542   1545\n",
       "             \n",
       "  2356   5689\n",
       " 11837  12920\n",
       "  5127   8482\n",
       "[torch.cuda.LongTensor of size 8405x2 (GPU 0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'narrative'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # spanish_embeddings\n",
    "# tgt_emb2=tgt_embeddings.cpu().numpy()\n",
    "# # print(tgt_emd.shape)\n",
    "src_id2word[5127]\n",
    "# tgt_id2word[8482]\n",
    "\n",
    "# def get_nn(word_emb, tgt_emb, tgt_id2word, K=5):\n",
    "  \n",
    "#     scores = (tgt_emb / np.linalg.norm(tgt_emb, 2, 1)[:, None]).dot(word_emb / np.linalg.norm(word_emb))\n",
    "#     k_best = scores.argsort()[-K:][::-1]\n",
    "#     for i, idx in enumerate(k_best):\n",
    "#         print('%.4f - %s' % (scores[idx], tgt_id2word[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_map(words,language):\n",
    "#     id2word={}\n",
    "#     for word in words:\n",
    "#         id=language.get_word_id(word)\n",
    "#         id2word[id]=word\n",
    "#     return id2word\n",
    "# spanish_map=create_map(Swords,spanish)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cat_embedding=mapping(Variable(src_embeddings[src_word2id['same']],requires_grad=False).cuda()).cpu().data\n",
    "# word_emd=cat_embedding.numpy()\n",
    "# get_nn(word_emd,tgt_emb,tgt_id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_embedding=tgt_embeddings[tgt_word2id['misma']]\n",
    "# word_emd=cat_embedding.numpy()\n",
    "# get_nn(word_emd,fake_src_embeddings.cpu().numpy(),src_id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_src_embeddings=(mapping(Variable(src_embedding, requires_grad=False).cuda())).cuda()\n",
    "# tgt_embeddings=(tgt_embeddings).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 0.07\n"
     ]
    }
   ],
   "source": [
    "fake_src_embeddings=torch.FloatTensor(fake_src_embeddings.cpu().data.numpy())\n",
    "# # type(fake_src_embeddings)\n",
    "# # src_embedding=src_embeddings.cpu().detach().numpy()\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, whiten=True)  # TSNE(n_components=2, n_iter=3000, verbose=2)\n",
    "pca.fit(np.vstack([fake_src_embeddings, tgt_embedding]))\n",
    "print('Variance explained: %.2f' % pca.explained_variance_ratio_.sum())\n",
    "# src_emb=fake_src_embeddings/fake_src_embeddings.norm(2, 1, keepdim=True).expand_as(fake_src_embeddings)\n",
    "# tgt_emb = tgt_embeddings / tgt_embeddings.norm(2, 1, keepdim=True).expand_as(tgt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_similar_word(src_words, src_word2id, src_emb, tgt_words, tgt_word2id, tgt_emb, pca):\n",
    "\n",
    "    Y = []\n",
    "    word_labels = []\n",
    "    for sw in src_words:\n",
    "        Y.append(src_emb[src_word2id[sw]])\n",
    "        word_labels.append(sw)\n",
    "    for tw in tgt_words:\n",
    "        Y.append(tgt_emb[tgt_word2id[tw]])\n",
    "        word_labels.append(tw)\n",
    "\n",
    "    # find tsne coords for 2 dimensions\n",
    "    Y = pca.transform(Y)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "\n",
    "    # display scatter plot\n",
    "    plt.figure(figsize=(10, 8), dpi=80)\n",
    "    plt.scatter(x_coords, y_coords, marker='x')\n",
    "\n",
    "    for k, (label, x, y) in enumerate(zip(word_labels, x_coords, y_coords)):\n",
    "        color = 'blue' if k < len(src_words) else 'red'  # src words in blue / tgt words in red\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points', fontsize=19,\n",
    "                     color=color, weight='bold')\n",
    "\n",
    "    plt.xlim(x_coords.min() - 0.2, x_coords.max() + 0.2)\n",
    "    plt.ylim(y_coords.min() - 0.2, y_coords.max() + 0.2)\n",
    "    plt.title('Visualization of the multilingual word embedding space')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "src_words = ['human', 'the',   'viewed', 'building','research','cat','tennis']\n",
    "tgt_words = ['humano', 'el', 'visto', 'edificio',u'investigacin','gato',u'tenis']\n",
    "\n",
    "plot_similar_word(src_words,src_word2id,fake_src_embeddings.cpu().numpy(),tgt_words,tgt_word2id,tgt_embedding.cpu().numpy(),pca)\n",
    "# # english.get_word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dico=create_dictionary(src_emb,tgt_emb)\n",
    "# print(type(src_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_src_embeddings2=(mapping(Variable(src_embeddings, requires_grad=False).cuda())).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_embedding=mapping(Variable(src_embeddings[src_word2id['the']],requires_grad=False).cuda()).cpu().data\n",
    "# word_emd=cat_embedding.numpy()\n",
    "# get_nn(word_emd,tgt_embeddings.cpu().numpy(),tgt_id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
