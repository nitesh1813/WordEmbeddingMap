{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pip\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "from torch.autograd import Variable\n",
    "import io\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_embeddings(path):\n",
    "    \"\"\"\n",
    "    Reload pretrained embeddings from a text file.\n",
    "    \"\"\"\n",
    "    word2id = {}\n",
    "    vectors = []\n",
    "    id2word={}\n",
    "    emb_path =path\n",
    "    _emb_dim_file = 300\n",
    "    with io.open(emb_path, 'r', encoding='utf-8', newline='\\n', errors='ignore') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 0:\n",
    "                split = line.split()\n",
    "               \n",
    "            else:\n",
    "                word, vect = line.rstrip().split(' ', 1)\n",
    "                \n",
    "                word = word.lower()\n",
    "                vect = np.fromstring(vect, sep=' ')\n",
    "                if np.linalg.norm(vect) == 0:  # avoid to have null embeddings\n",
    "                    vect[0] = 0.01\n",
    "               \n",
    "                word2id[word] = len(word2id)\n",
    "                id2word[len(word2id)]=word\n",
    "                vectors.append(vect[None])\n",
    "            if len(word2id) >= 200000:\n",
    "                break\n",
    "\n",
    "    \n",
    "    print(\"Loaded %i pre-trained word embeddings.\" % len(vectors))\n",
    "\n",
    "\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.concatenate(vectors, 0)\n",
    "    embeddings = torch.from_numpy(embeddings).float()\n",
    "    embeddings = embeddings\n",
    "    \n",
    "    return embeddings,word2id,id2word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dis_xy(bs, src_emb,tgt_emb):\n",
    "        \"\"\"\n",
    "        Get discriminator input batch / output target.\n",
    "        \"\"\"\n",
    "        # select random word IDs\n",
    "        #bs = self.params.batch_size\n",
    "        mf = 75000\n",
    "        #assert mf <= min(len(self.src_dico), len(self.tgt_dico))\n",
    "        src_ids = torch.LongTensor(bs).random_(mf)\n",
    "        tgt_ids = torch.LongTensor(bs).random_(mf)\n",
    "        \n",
    "        src_ids = src_ids.cuda()\n",
    "        tgt_ids = tgt_ids.cuda()\n",
    "\n",
    "        # get word embeddings\n",
    "        src_emb = src_emb(Variable(src_ids))\n",
    "        tgt_emb = tgt_emb(Variable(tgt_ids))\n",
    "        src_emb = mapping(Variable(src_emb.data))\n",
    "        tgt_emb = Variable(tgt_emb.data)\n",
    "\n",
    "        # input / target\n",
    "        x = torch.cat([src_emb, tgt_emb], 0)\n",
    "        y = torch.FloatTensor(2 * bs).zero_()\n",
    "        y[:bs] = 1 - 0.2\n",
    "        y[bs:] = 0.2\n",
    "        y = Variable(y.cuda())\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200000 pre-trained word embeddings.\n",
      "Loaded 200000 pre-trained word embeddings.\n"
     ]
    }
   ],
   "source": [
    "src_embedding,src_word2id,src_id2word=load_pretrained_embeddings(\"data/wiki.en.vec\")\n",
    "tgt_embedding,tgt_word2id,tgt_id2word=load_pretrained_embeddings(\"data/wiki.es.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(200000, 300, sparse=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_embeddings = nn.Embedding(200000, 300, sparse=True)\n",
    "src_embeddings.weight.data.copy_(src_embedding)\n",
    "\n",
    "tgt_embeddings = nn.Embedding(200000, 300, sparse=True)\n",
    "tgt_embeddings.weight.data.copy_(tgt_embedding)\n",
    "\n",
    "src_embeddings.cuda()\n",
    "tgt_embeddings.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_batch2(X,batch_size):\n",
    " \n",
    "#     N = X.size()[0]\n",
    "    N=200000\n",
    "    batch_indices = torch.LongTensor( np.random.randint(0,N,size=batch_size) )\n",
    "\n",
    "    batch_xs = X(Variable(batch_indices).cuda())\n",
    "\n",
    "    return batch_xs.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, dis_hid_dim,dis_dropout,dis_input_dropout):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.emb_dim = 300\n",
    "        self.dis_layers = 2\n",
    "        self.dis_hid_dim = dis_hid_dim\n",
    "        self.dis_dropout = dis_dropout\n",
    "        self.dis_input_dropout = dis_input_dropout\n",
    "\n",
    "        layers = [nn.Dropout(self.dis_input_dropout)]\n",
    "        for i in range(self.dis_layers + 1):\n",
    "            input_dim = self.emb_dim if i == 0 else self.dis_hid_dim\n",
    "            output_dim = 1 if i == self.dis_layers else self.dis_hid_dim\n",
    "            layers.append(nn.Linear(input_dim, output_dim))\n",
    "            if i < self.dis_layers:\n",
    "                layers.append(nn.LeakyReLU(0.2))\n",
    "                layers.append(nn.Dropout(self.dis_dropout))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.dim() == 2 and x.size(1) == self.emb_dim\n",
    "        return self.layers(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Orthogonal(mapping,beta):\n",
    "    W=mapping.weight.data\n",
    "    mapping.weight.data.copy_((1 + beta) * W - beta * W.mm(W.transpose(0, 1).mm(W)))\n",
    "    return mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (layers): Sequential(\n",
       "    (0): Dropout(p=0.1)\n",
       "    (1): Linear(in_features=300, out_features=2048, bias=True)\n",
       "    (2): LeakyReLU(0.2)\n",
       "    (3): Dropout(p=0)\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): LeakyReLU(0.2)\n",
       "    (6): Dropout(p=0)\n",
       "    (7): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (8): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up linear mapping,\n",
    "mapping = nn.Linear(300, 300, bias=False)\n",
    "mapping.weight.data.copy_(torch.eye(300))\n",
    "modelDisc= Discriminator(2048,0,0.1)\n",
    "mapping.cuda()\n",
    "modelDisc.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csls(src_emb, tgt_emb, knn=10):\n",
    " \n",
    "    bs = 1024\n",
    "    all_distances = []\n",
    "#     emb = tgt_emb.transpose(0, 1).contiguous()\n",
    "    emb=tgt_emb.transpose(0,1)\n",
    "    for i in range(0, src_emb.shape[0], bs):\n",
    "        distances = src_emb[i:i + bs].mm(emb)\n",
    "        best_distances, _ = distances.topk(knn, dim=1, largest=True, sorted=True)\n",
    "        all_distances.append(best_distances.mean(1).cpu())\n",
    "    all_distances = torch.cat(all_distances)\n",
    "    return all_distances.numpy()\n",
    "\n",
    "def get_neighbour(emb1,emb2):\n",
    "    bs = 128\n",
    "\n",
    "    all_scores = []\n",
    "    all_targets = []\n",
    "\n",
    "    # number of source words to consider\n",
    "    n_src = emb1.size(0)\n",
    "    n_src =30000\n",
    "    knn = 10\n",
    "\n",
    "        # average distances to k nearest neighbors\n",
    "    average_dist1 = torch.from_numpy(get_csls(emb1, emb2, knn))\n",
    "    average_dist2 = torch.from_numpy(get_csls(emb2, emb1, knn))\n",
    "    average_dist1 = average_dist1.type_as(emb1)\n",
    "    average_dist2 = average_dist2.type_as(emb2)\n",
    "\n",
    "    # for every source word\n",
    "    for i in range(0, n_src, bs):\n",
    "\n",
    "        # compute target words scores\n",
    "        scores = emb2.mm(emb1[i:min(n_src, i + bs)].transpose(0, 1)).transpose(0, 1)\n",
    "        scores.mul_(2)\n",
    "        scores.sub_(average_dist1[i:min(n_src, i + bs)][:, None] + average_dist2[None, :])\n",
    "        best_scores, best_targets = scores.topk(2, dim=1, largest=True, sorted=True)\n",
    "\n",
    "        # update scores / potential targets\n",
    "        all_scores.append(best_scores.cpu())\n",
    "        all_targets.append(best_targets.cpu())\n",
    "\n",
    "    all_scores = torch.cat(all_scores, 0)\n",
    "    all_targets = torch.cat(all_targets, 0)\n",
    "\n",
    "    all_pairs = torch.cat([torch.arange(0, all_targets.size(0)).long().unsqueeze(1),all_targets[:, 0].unsqueeze(1)], 1)\n",
    "    assert all_scores.size() == all_pairs.size() == (n_src, 2)\n",
    "\n",
    "    # sort pairs by score confidence\n",
    "    diff = all_scores[:, 0] - all_scores[:, 1]\n",
    "    reordered = diff.sort(0, descending=True)[1]\n",
    "    all_scores = all_scores[reordered]\n",
    "    all_pairs = all_pairs[reordered]\n",
    "    \n",
    "    \n",
    "    selected = all_pairs.max(1)[0] <= 30000\n",
    "    mask = selected.unsqueeze(1).expand_as(all_scores).clone()\n",
    "    all_scores = all_scores.masked_select(mask).view(-1, 2)\n",
    "    all_pairs = all_pairs.masked_select(mask).view(-1, 2)\n",
    "    return all_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dictionary(src_embedding,tgt_embedding):\n",
    "    src2tgt = get_neighbour(src_embedding,tgt_embedding)\n",
    "    tgt2src = get_neighbour(tgt_embedding,src_embedding)\n",
    "    \n",
    "    tgt2src = torch.cat([tgt2src[:, 1:], tgt2src[:, :1]], 1)\n",
    "    \n",
    "    s2t_candidates = set([(a, b) for a, b in src2tgt])\n",
    "    t2s_candidates = set([(a, b) for a, b in tgt2src])\n",
    "#     print(s2t_candidates)\n",
    "    final_pairs = s2t_candidates & t2s_candidates\n",
    "    if len(final_pairs) == 0:\n",
    "        print(\"warning\")\n",
    "        return None\n",
    "    dictionary = torch.LongTensor(list([[a, b] for (a, b) in final_pairs]))\n",
    "\n",
    "    print('New train dictionary of %i pairs.' % dictionary.size(0))\n",
    "    return dictionary.cuda()\n",
    "    \n",
    "        \n",
    "# def build_dictionary(src_emb, tgt_emb, _params, s2t_candidates, t2s_candidates):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_metric(src_embs, tgt_embs):\n",
    "     \n",
    "        indices= torch.LongTensor(np.arange(200000))\n",
    "        batch_xs = src_embs(Variable(indices).cuda())\n",
    "        src_emb = mapping(batch_xs.cuda())\n",
    "        src_emb=torch.FloatTensor(src_emb.cpu().data.numpy()).cuda()\n",
    "        tgt_emb = tgt_embs(Variable(indices).cuda())\n",
    "        tgt_emb=torch.FloatTensor(tgt_emb.cpu().data.numpy()).cuda()\n",
    "        src_emb = src_emb / src_emb.norm(2, 1, keepdim=True).expand_as(src_emb)\n",
    "        tgt_emb = tgt_emb / tgt_emb.norm(2, 1, keepdim=True).expand_as(tgt_emb)\n",
    "        print(type(src_emb))\n",
    "\n",
    "        #s2t_candidates = get_candidates(src_emb, tgt_emb, _params)\n",
    "        #t2s_candidates = get_candidates(tgt_emb, src_emb, _params)\n",
    "        \n",
    "        dictionary = create_dictionary(src_emb, tgt_emb)\n",
    "        dictionary_max_size = 10000\n",
    "        if dictionary is None:\n",
    "            mean_cosine=0\n",
    "        else:\n",
    "            mean_cosine = (src_emb[dictionary[:dictionary_max_size, 0]] * tgt_emb[dictionary[:dictionary_max_size, 1]]).sum(1).mean()\n",
    "        print(\"Mean cosine\", mean_cosine)\n",
    "        return mean_cosine\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "linoptimizer = torch.optim.SGD(mapping.parameters(), lr=0.1)\n",
    "discoptimizer= torch.optim.SGD(modelDisc.parameters(), lr=0.1)\n",
    "\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "\n",
    "def get_xy():\n",
    "#get minibatch of spanish words\n",
    "    spanish_batch=get_batch2(tgt_embeddings,batch_size)\n",
    "    #getminibatch of english words\n",
    "    english_batch=get_batch2(src_embeddings,batch_size)\n",
    "\n",
    "    #generate fake spanish embeddings\n",
    "    s_fake= mapping(english_batch)\n",
    "\n",
    "    #stack real and fake\n",
    "    x = torch.cat([s_fake, spanish_batch], 0)\n",
    "    #         print(x.shape)\n",
    "    y = torch.FloatTensor(2 * batch_size).zero_()\n",
    "    \n",
    "    y[batch_size:] = 0.2\n",
    "    y[:batch_size]=1-0.2\n",
    "    y=Variable(y).cuda()\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.3204269409\n",
      "(0, ' Discriminator Loss :  ', \n",
      " 0.6736\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 0.7218\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "17.2290706635\n",
      "(4000, ' Discriminator Loss :  ', \n",
      " 0.6125\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 0.8372\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "17.0373191833\n",
      "(8000, ' Discriminator Loss :  ', \n",
      " 0.5586\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1799\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.8897361755\n",
      "(12000, ' Discriminator Loss :  ', \n",
      " 0.5679\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0062\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.759645462\n",
      "(16000, ' Discriminator Loss :  ', \n",
      " 0.6361\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0220\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.6194076538\n",
      "(20000, ' Discriminator Loss :  ', \n",
      " 0.5901\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0524\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.5000457764\n",
      "(24000, ' Discriminator Loss :  ', \n",
      " 0.5711\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0042\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.3904762268\n",
      "(28000, ' Discriminator Loss :  ', \n",
      " 0.5873\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 0.9896\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.2930107117\n",
      "(32000, ' Discriminator Loss :  ', \n",
      " 0.5952\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 0.9793\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.225276947\n",
      "(36000, ' Discriminator Loss :  ', \n",
      " 0.5956\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0834\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1727581024\n",
      "(40000, ' Discriminator Loss :  ', \n",
      " 0.5790\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0633\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1394538879\n",
      "(44000, ' Discriminator Loss :  ', \n",
      " 0.5842\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1268\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1164264679\n",
      "(48000, ' Discriminator Loss :  ', \n",
      " 0.5716\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0562\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1074199677\n",
      "(52000, ' Discriminator Loss :  ', \n",
      " 0.5461\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1208\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0927886963\n",
      "(56000, ' Discriminator Loss :  ', \n",
      " 0.5841\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1437\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.081035614\n",
      "(60000, ' Discriminator Loss :  ', \n",
      " 0.5781\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1515\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0503196716\n",
      "(64000, ' Discriminator Loss :  ', \n",
      " 0.5480\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1410\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.049533844\n",
      "(68000, ' Discriminator Loss :  ', \n",
      " 0.5734\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2032\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0574169159\n",
      "(72000, ' Discriminator Loss :  ', \n",
      " 0.5597\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.0751\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0764884949\n",
      "(76000, ' Discriminator Loss :  ', \n",
      " 0.5827\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1432\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0843524933\n",
      "(80000, ' Discriminator Loss :  ', \n",
      " 0.5841\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1356\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0847530365\n",
      "(84000, ' Discriminator Loss :  ', \n",
      " 0.5716\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1498\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.085893631\n",
      "(88000, ' Discriminator Loss :  ', \n",
      " 0.5819\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1660\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.096818924\n",
      "(92000, ' Discriminator Loss :  ', \n",
      " 0.5527\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1701\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0978317261\n",
      "(96000, ' Discriminator Loss :  ', \n",
      " 0.5611\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1183\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0964813232\n",
      "(100000, ' Discriminator Loss :  ', \n",
      " 0.5691\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1886\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.0960521698\n",
      "(104000, ' Discriminator Loss :  ', \n",
      " 0.5676\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2857\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1066226959\n",
      "(108000, ' Discriminator Loss :  ', \n",
      " 0.5577\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1452\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1067256927\n",
      "(112000, ' Discriminator Loss :  ', \n",
      " 0.5532\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1929\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1081504822\n",
      "(116000, ' Discriminator Loss :  ', \n",
      " 0.6003\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1795\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1112232208\n",
      "(120000, ' Discriminator Loss :  ', \n",
      " 0.5598\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1414\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1204204559\n",
      "(124000, ' Discriminator Loss :  ', \n",
      " 0.5666\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2013\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1410255432\n",
      "(128000, ' Discriminator Loss :  ', \n",
      " 0.5944\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1403\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.157749176\n",
      "(132000, ' Discriminator Loss :  ', \n",
      " 0.5746\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2084\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1601924896\n",
      "(136000, ' Discriminator Loss :  ', \n",
      " 0.5796\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1540\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1501560211\n",
      "(140000, ' Discriminator Loss :  ', \n",
      " 0.5493\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1626\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1573295593\n",
      "(144000, ' Discriminator Loss :  ', \n",
      " 0.5647\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2149\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1520595551\n",
      "(148000, ' Discriminator Loss :  ', \n",
      " 0.5528\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2401\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1350040436\n",
      "(152000, ' Discriminator Loss :  ', \n",
      " 0.5576\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2093\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.129983902\n",
      "(156000, ' Discriminator Loss :  ', \n",
      " 0.5445\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1234\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.13240242\n",
      "(160000, ' Discriminator Loss :  ', \n",
      " 0.5597\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.1472\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "16.1502361298\n",
      "(164000, ' Discriminator Loss :  ', \n",
      " 0.5395\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n",
      "('Generator Loss : ', \n",
      " 1.2585\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-60c386095a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mloss2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mlinoptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mlinoptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iterations_per_epoch=1000000\n",
    "batch_size=32\n",
    "epoch=2\n",
    "val_score=-1\n",
    "\n",
    "for _ in range(epoch):\n",
    "      \n",
    "    for _n in range(0,iterations_per_epoch,batch_size):\n",
    "        modelDisc.train()\n",
    "        mapping.eval()\n",
    "        for __ in range(5):\n",
    "\n",
    "            x,y=get_xy()\n",
    "            #x,y=get_dis_xy(32,src_embeddings,tgt_embeddings)\n",
    "            y_pred = modelDisc(Variable(x.data))\n",
    "       \n",
    "\n",
    "\n",
    "            loss= loss_fn(y_pred, y)\n",
    "\n",
    "            discoptimizer.zero_grad()\n",
    "\n",
    "\n",
    "       \n",
    "            loss.backward()\n",
    "    #         print(loss.data)\n",
    "\n",
    "           \n",
    "            discoptimizer.step()\n",
    "          \n",
    "        modelDisc.eval()\n",
    "        mapping.train()\n",
    "        for __ in range(1):\n",
    "            \n",
    "            x,y=get_xy()\n",
    "            #x,y=get_dis_xy(32,src_embeddings,tgt_embeddings)\n",
    "            y=1-y\n",
    "            y_pred = modelDisc(x)\n",
    "            loss2= loss_fn(y_pred, y)\n",
    "            linoptimizer.zero_grad()\n",
    "            loss2.backward()\n",
    "            linoptimizer.step()\n",
    "\n",
    "            mapping=Orthogonal(mapping,0.001)\n",
    "        if _n%500==0:\n",
    "            print(torch.norm(mapping.weight.data,2))\n",
    "            print(_n,\" Discriminator Loss :  \",loss.data)\n",
    "            print(\"Generator Loss : \", loss2.data)\n",
    "        \n",
    "    val=evaluation_metric(src_embeddings,tgt_embeddings)\n",
    "    if val_score<val:\n",
    "        torch.save(mapping.state_dict(), './mapping.pth')\n",
    "        val_score=val\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New train dictionary of 1737 pairs.\n"
     ]
    }
   ],
   "source": [
    "def build_dictionary(src_emb,tgt_emb):\n",
    "    src_emb = mapping(Variable(src_emb, requires_grad=False).cuda())\n",
    "    src_emb=torch.FloatTensor(src_emb.cpu().data.numpy()).cuda()\n",
    "    tgt_emb = tgt_emb.cuda()\n",
    "    src_emb = src_emb / src_emb.norm(2, 1, keepdim=True).expand_as(src_emb)\n",
    "    tgt_emb = tgt_emb / tgt_emb.norm(2, 1, keepdim=True).expand_as(tgt_emb)\n",
    "\n",
    "\n",
    "#         s2t_candidates = get_candidates(src_emb, tgt_emb, _params)\n",
    "#         t2s_candidates = get_candidates(tgt_emb, src_emb, _params)\n",
    "    dictionary= create_dictionary(src_emb, tgt_emb)\n",
    "    return dictionary\n",
    "\n",
    "dictionary=build_dictionary(src_embedding,tgt_embedding)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes(src_emb,tgt_emb):\n",
    "    A = src_emb.weight.data[list(dictionary[:, 0])]\n",
    "    B = tgt_emb.weight.data[list(dictionary[:, 1])]\n",
    "    M = B.transpose(0, 1).mm(A).cpu().numpy()\n",
    "    U, S, V_t = linalg.svd(M, full_matrices=True)\n",
    "    mapping.weight.data.copy_(torch.from_numpy(U.dot(V_t)).type_as(mapping.weight.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "New train dictionary of 14371 pairs.\n",
      "('Mean cosine', 0.7212909460067749)\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "New train dictionary of 14371 pairs.\n",
      "('Mean cosine', 0.7212909460067749)\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "New train dictionary of 14371 pairs.\n",
      "('Mean cosine', 0.7212909460067749)\n",
      "<class 'torch.cuda.FloatTensor'>\n",
      "New train dictionary of 14371 pairs.\n",
      "('Mean cosine', 0.7212909460067749)\n",
      "<class 'torch.cuda.FloatTensor'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-7cc873514a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprocrustes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluation_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevaluation_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_score\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-af316bc03aa3>\u001b[0m in \u001b[0;36mevaluation_metric\u001b[0;34m(src_embs, tgt_embs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m#t2s_candidates = get_candidates(tgt_emb, src_emb, _params)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdictionary_max_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-d92acee9676c>\u001b[0m in \u001b[0;36mcreate_dictionary\u001b[0;34m(src_embedding, tgt_embedding)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msrc2tgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtgt_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtgt2src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msrc_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtgt2src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt2src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt2src\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-9f250be66999>\u001b[0m in \u001b[0;36mget_neighbour\u001b[0;34m(emb1, emb2)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# update scores / potential targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mall_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/tensor.pyc\u001b[0m in \u001b[0;36mcpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34mr\"\"\"Returns a CPU copy of this tensor if it's not already on the CPU\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/cuda/__init__.pyc\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    procrustes(src_embeddings,tgt_embeddings)\n",
    "    evaluation_metric(src_embeddings.cuda(),tgt_embeddings.cuda())\n",
    "    val=evaluation_metric(src_embeddings,tgt_embeddings)\n",
    "    if val_score<val:\n",
    "        torch.save(mapping.state_dict(), './mapping.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # spanish_embeddings\n",
    "# tgt_emb2=tgt_embeddings.cpu().numpy()\n",
    "# # print(tgt_emd.shape)\n",
    "\n",
    "\n",
    "# def get_nn(word_emb, tgt_emb, tgt_id2word, K=5):\n",
    "  \n",
    "#     scores = (tgt_emb / np.linalg.norm(tgt_emb, 2, 1)[:, None]).dot(word_emb / np.linalg.norm(word_emb))\n",
    "#     k_best = scores.argsort()[-K:][::-1]\n",
    "#     for i, idx in enumerate(k_best):\n",
    "#         print('%.4f - %s' % (scores[idx], tgt_id2word[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_map(words,language):\n",
    "#     id2word={}\n",
    "#     for word in words:\n",
    "#         id=language.get_word_id(word)\n",
    "#         id2word[id]=word\n",
    "#     return id2word\n",
    "# spanish_map=create_map(Swords,spanish)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cat_embedding=mapping(Variable(src_embeddings[src_word2id['same']],requires_grad=False).cuda()).cpu().data\n",
    "# word_emd=cat_embedding.numpy()\n",
    "# get_nn(word_emd,tgt_emb,tgt_id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_embedding=tgt_embeddings[tgt_word2id['misma']]\n",
    "# word_emd=cat_embedding.numpy()\n",
    "# get_nn(word_emd,fake_src_embeddings.cpu().numpy(),src_id2word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_src_embeddings=(mapping(Variable(src_embedding, requires_grad=False).cuda())).cuda()\n",
    "# tgt_embeddings=(tgt_embeddings).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 0.07\n"
     ]
    }
   ],
   "source": [
    "fake_src_embeddings=torch.FloatTensor(fake_src_embeddings.cpu().data.numpy())\n",
    "# # type(fake_src_embeddings)\n",
    "# # src_embedding=src_embeddings.cpu().detach().numpy()\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, whiten=True)  # TSNE(n_components=2, n_iter=3000, verbose=2)\n",
    "pca.fit(np.vstack([fake_src_embeddings, tgt_embedding]))\n",
    "print('Variance explained: %.2f' % pca.explained_variance_ratio_.sum())\n",
    "# src_emb=fake_src_embeddings/fake_src_embeddings.norm(2, 1, keepdim=True).expand_as(fake_src_embeddings)\n",
    "# tgt_emb = tgt_embeddings / tgt_embeddings.norm(2, 1, keepdim=True).expand_as(tgt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_similar_word(src_words, src_word2id, src_emb, tgt_words, tgt_word2id, tgt_emb, pca):\n",
    "\n",
    "    Y = []\n",
    "    word_labels = []\n",
    "    for sw in src_words:\n",
    "        Y.append(src_emb[src_word2id[sw]])\n",
    "        word_labels.append(sw)\n",
    "    for tw in tgt_words:\n",
    "        Y.append(tgt_emb[tgt_word2id[tw]])\n",
    "        word_labels.append(tw)\n",
    "\n",
    "    # find tsne coords for 2 dimensions\n",
    "    Y = pca.transform(Y)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "\n",
    "    # display scatter plot\n",
    "    plt.figure(figsize=(10, 8), dpi=80)\n",
    "    plt.scatter(x_coords, y_coords, marker='x')\n",
    "\n",
    "    for k, (label, x, y) in enumerate(zip(word_labels, x_coords, y_coords)):\n",
    "        color = 'blue' if k < len(src_words) else 'red'  # src words in blue / tgt words in red\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points', fontsize=19,\n",
    "                     color=color, weight='bold')\n",
    "\n",
    "    plt.xlim(x_coords.min() - 0.2, x_coords.max() + 0.2)\n",
    "    plt.ylim(y_coords.min() - 0.2, y_coords.max() + 0.2)\n",
    "    plt.title('Visualization of the multilingual word embedding space')\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# src_words = ['dog', 'the', 'me', 'tennis', 'cat', 'conference']\n",
    "# tgt_words = ['perro', 'el', 'yo', u'tenis',  'gato', 'conferencia']\n",
    "src_words = ['building',  'history', 'tennis', 'research', 'conference']\n",
    "tgt_words = ['edifico', 'historia', u'tenis',  u'investigacin', 'conferencia']\n",
    "plot_similar_word(src_words,src_word2id,fake_src_embeddings.cpu().numpy(),tgt_words,tgt_word2id,tgt_embedding.cpu().numpy(),pca)\n",
    "# # english.get_word_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dico=create_dictionary(src_emb,tgt_emb)\n",
    "# print(type(src_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_src_embeddings2=(mapping(Variable(src_embeddings, requires_grad=False).cuda())).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_embedding=mapping(Variable(src_embeddings[src_word2id['the']],requires_grad=False).cuda()).cpu().data\n",
    "# word_emd=cat_embedding.numpy()\n",
    "# get_nn(word_emd,tgt_embeddings.cpu().numpy(),tgt_id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.cuda.FloatTensor'>\n",
      "New train dictionary of 11977 pairs.\n",
      "('Mean cosine', 0.6451402902603149)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6451402902603149"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_metric(src_embeddings,tgt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
